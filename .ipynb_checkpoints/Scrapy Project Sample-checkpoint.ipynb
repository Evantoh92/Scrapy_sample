{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapy Project Sample\n",
    "\n",
    "This is my first project demonstrating the use of scrapy spiders to scrap data using a sample URL: http://chubbygrub.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Brief outline of initializing the scrapy spider\n",
    "\n",
    "Install the Scrapy package using `conda install scrapy`. In this case, we'll specify XPath, as our query will utilize XPath language. CSS can be used as well along with the selector gadget on chrome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the terminal, create new Scrapy project by `cd` into desired directory. Then type `>scrapy startproject chubby`. Project name in this case is chubby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an item. We will be navigating into the `items.py` file under the chubby folder using VS code. Upon opening the file, we need to define the item, i.e. what information headers would you want to scrape?\n",
    "\n",
    "```python\n",
    "import scrapy\n",
    "\n",
    "class ChubbyItem(scrapy.Item):\n",
    "    # Define the fields for your item here like:\n",
    "    # name = scrapy.Field()\n",
    "    calories = scrapy.Field()\n",
    "    carbs = scrapy.Field()\n",
    "    category = scrapy.Field()\n",
    "    name = scrapy.Field()\n",
    "    restaurant = scrapy.Field()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Identifying the target/sample:\n",
    "\n",
    "```python\n",
    "foods = [\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Using the documentation and Xpath helper, select the right information\n",
    "\n",
    "```python\n",
    "import scrapy\n",
    "from chubby.items import ChubbyItem\n",
    "\n",
    "class ChubbySpider(scrapy.Spider):\n",
    "    name = \"chubby\"\n",
    "    start_urls = [\n",
    "        \"http://www.chubbygrub.com/\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response): # Define parse() function. \n",
    "        #follow url to restaurant page for each restaurant to obtain the menu\n",
    "        for url in response.xpath('/html/body/div[4]/div/div/div/a/@href'):\n",
    "        #initiate another parse to 'execute' the queries on the new url\n",
    "            yield response.follow(url, self.parse_author)\n",
    "    \n",
    "    #We are now on each individual restaurant menu page.\n",
    "    def parse_author(self, response):\n",
    "        items = []\n",
    "        for i in response.xpath('//*[@id=\"items\"]/tbody/tr'):\n",
    "            item = ChubbyItem()\n",
    "            item['calories'] = i.xpath('./td[3]/text()').get()\n",
    "            item['name'] = i.xpath('./td[1]/text()').get()\n",
    "            item['carbs'] = i.xpath('./td[5]/text()').get()\n",
    "            item['category'] = i.xpath('./td[2]/a/text()').get()\n",
    "            #restaurant does not follow the path specified in for loop but using the absolute path works\n",
    "            item['restaurant'] = response.xpath('/html/body/div[2]/div[1]/div/div/h1/span/text()').get()\n",
    "            items.append(item)\n",
    "        return items\n",
    " \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run the spider\n",
    "\n",
    "Under terminal when `chubby_spider.py` is opened in VS code, type `>scrapy crawl chubby` to run the spider. Errors encountered are fairly common. Hence it is advisable to try out using `>scrapy shell 'website-name'` with the Xpath queries first to understand how it works first before crawling each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save the output into a `.csv` file\n",
    "\n",
    "Still under the terminal, type the following where `items.csv` is the desired file name. \n",
    "<blockquote>\n",
    "```\n",
    "> scrapy crawl craigslist -o items.csv -t csv\n",
    "```\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
